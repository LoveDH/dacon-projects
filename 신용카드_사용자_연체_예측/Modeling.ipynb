{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, gc, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import  log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 1000\n",
    "# pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "SEED = 2021\n",
    "# seed_everything(SEED)\n",
    "TARGET = 'credit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"data/train_adjusted.pkl\")\n",
    "test = pd.read_pickle(\"data/test_adjusted.pkl\")\n",
    "sub = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train.drop(['index','credit'],1), test.drop(['index'],1)], axis=0)\n",
    "df['DAYS_BIRTH_DAYS_EMPLOYED_ratio'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['income_total_DAYS_BIRTH_ratio'] = df['income_total'] / df['DAYS_BIRTH']\n",
    "df['income_total_DAYS_EMPLOYED_ratio'] = df['income_total'] / df['DAYS_EMPLOYED']\n",
    "df['parents'] = df['family_size'] - df['child_num']\n",
    "df['income_total_family_size_ratio'] = df['income_total'] / df['family_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('card_ID',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 8 14\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [x for x in df.columns if df[x].dtype == 'object']\n",
    "num_cols = [x for x in df.columns if x not in cat_cols + [TARGET]]\n",
    "feature_cols = num_cols + cat_cols\n",
    "print(len(feature_cols), len(cat_cols), len(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = lbe.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "encoding_dim = 64\n",
    "\n",
    "def get_model(encoding_dim, dropout=.2):\n",
    "    num_dim = len(num_cols)\n",
    "    num_input = keras.layers.Input((num_dim,), name='num_input')\n",
    "    cat_inputs = []\n",
    "    cat_embs = []\n",
    "    emb_dims = 0\n",
    "    for col in cat_cols:\n",
    "        cat_input = keras.layers.Input((1,), name=f'{col}_input')\n",
    "        emb_dim = max(8, int(np.log2(1 + df[col].nunique()) * 4))\n",
    "        cat_emb = keras.layers.Embedding(input_dim=df[col].max() + 1, output_dim=emb_dim)(cat_input)\n",
    "        cat_emb = keras.layers.Dropout(dropout)(cat_emb)\n",
    "        cat_emb = keras.layers.Reshape((emb_dim,))(cat_emb)\n",
    "\n",
    "        cat_inputs.append(cat_input)\n",
    "        cat_embs.append(cat_emb)\n",
    "        emb_dims += emb_dim\n",
    "\n",
    "    merged_inputs = keras.layers.Concatenate()([num_input] + cat_embs)\n",
    "\n",
    "    encoded = keras.layers.Dense(encoding_dim * 3, activation='relu')(merged_inputs)\n",
    "    encoded = keras.layers.Dropout(dropout)(encoded)\n",
    "    encoded = keras.layers.Dense(encoding_dim * 2, activation='relu')(encoded)\n",
    "    encoded = keras.layers.Dropout(dropout)(encoded)    \n",
    "    encoded = keras.layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "    \n",
    "    decoded = keras.layers.Dense(encoding_dim * 2, activation='relu')(encoded)\n",
    "    decoded = keras.layers.Dropout(dropout)(decoded)\n",
    "    decoded = keras.layers.Dense(encoding_dim * 3, activation='relu')(decoded)\n",
    "    decoded = keras.layers.Dropout(dropout)(decoded)    \n",
    "    decoded = keras.layers.Dense(num_dim + emb_dims, activation='linear')(encoded)\n",
    "\n",
    "    encoder = keras.Model([num_input] + cat_inputs, encoded)\n",
    "    ae = keras.Model([num_input] + cat_inputs, decoded)\n",
    "    ae.add_loss(keras.losses.mean_squared_error(merged_inputs, decoded))\n",
    "    ae.compile(optimizer='adam')\n",
    "    return ae, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "gender_input (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "car_input (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reality_input (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "income_type_input (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edu_type_input (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "family_type_input (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "house_type_input (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "occyp_type_input (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 8)         16          gender_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 8)         16          car_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 8)         16          reality_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 10)        50          income_type_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 10)        50          edu_type_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 10)        50          family_type_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 11)        66          house_type_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 17)        323         occyp_type_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 8)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 8)         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 8)         0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 10)        0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1, 10)        0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1, 10)        0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 11)        0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1, 17)        0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "num_input (InputLayer)          [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 8)            0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 8)            0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 8)            0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10)           0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 11)           0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 17)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           num_input[0][0]                  \n",
      "                                                                 reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 192)          18624       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 192)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          24704       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 96)           6240        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 96)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (None, 96)           0           tf.convert_to_tensor[0][0]       \n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None,)              0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              (None,)              0           tf.math.reduce_mean[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 58,411\n",
      "Trainable params: 58,411\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae, encoder = get_model(encoding_dim)\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [df[num_cols].values] + [df[x].values for x in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 2s/step - loss: 722106624.0000 - val_loss: 612847936.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 636383040.0000 - val_loss: 554735872.0000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 576393898.6667 - val_loss: 504098368.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 525833749.3333 - val_loss: 456188704.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 483799626.6667 - val_loss: 411222464.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 441225696.0000 - val_loss: 364452800.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 393959722.6667 - val_loss: 310705696.0000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 348037461.3333 - val_loss: 258736176.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 302641856.0000 - val_loss: 213358224.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 261082016.0000 - val_loss: 172319584.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 223060341.3333 - val_loss: 136287680.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 189695114.6667 - val_loss: 108003640.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 161494464.0000 - val_loss: 88313080.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 141299296.0000 - val_loss: 75483632.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 126087008.0000 - val_loss: 67537160.0000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 116804629.3333 - val_loss: 62936840.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 110936064.0000 - val_loss: 60274652.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 104944778.6667 - val_loss: 58091240.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 100937848.0000 - val_loss: 55449820.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 96002949.3333 - val_loss: 52571044.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 90400554.6667 - val_loss: 49707684.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 85830314.6667 - val_loss: 46947236.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 81951136.0000 - val_loss: 44345924.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 77603682.6667 - val_loss: 42270388.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 75213018.6667 - val_loss: 40569000.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 71955848.0000 - val_loss: 39147572.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 69439616.0000 - val_loss: 37765280.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 66264522.6667 - val_loss: 36290660.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 64035478.6667 - val_loss: 34626724.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 61601005.3333 - val_loss: 32571398.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 59313445.3333 - val_loss: 30472474.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 56532848.0000 - val_loss: 28769328.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 54042034.6667 - val_loss: 27291646.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 51684904.0000 - val_loss: 25809582.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 264ms/step - loss: 49768316.0000 - val_loss: 24233642.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 47618784.0000 - val_loss: 22743728.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 45899817.3333 - val_loss: 21698352.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 43931566.6667 - val_loss: 20685976.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 42338933.3333 - val_loss: 19588284.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 40619457.3333 - val_loss: 18546238.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 39360208.0000 - val_loss: 17864356.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 38142885.3333 - val_loss: 17302102.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 37075504.0000 - val_loss: 16569247.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 35963144.0000 - val_loss: 15886044.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 35085558.6667 - val_loss: 15552889.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 34269130.6667 - val_loss: 15151022.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 33732150.6667 - val_loss: 14499884.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 32855660.0000 - val_loss: 14144746.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 31893792.0000 - val_loss: 13793298.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 31094036.6667 - val_loss: 13158749.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 30405954.6667 - val_loss: 12567939.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 29819476.0000 - val_loss: 12148870.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 28678710.6667 - val_loss: 11878804.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 28230165.3333 - val_loss: 11303273.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 27757545.3333 - val_loss: 10721644.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 26924024.6667 - val_loss: 10317578.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 25882785.3333 - val_loss: 9885050.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 25172329.3333 - val_loss: 9169612.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 24449409.3333 - val_loss: 8513485.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 23709772.0000 - val_loss: 8331032.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 22967133.3333 - val_loss: 7606096.5000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 22407491.3333 - val_loss: 6730615.5000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 21698465.3333 - val_loss: 6485890.5000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 21095084.6667 - val_loss: 6003258.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 20140253.3333 - val_loss: 5290921.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 19601344.0000 - val_loss: 4805184.5000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 19285394.0000 - val_loss: 4224931.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 18310690.6667 - val_loss: 3799412.2500\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 17710354.0000 - val_loss: 3567247.7500\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 17350654.6667 - val_loss: 3333154.2500\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 17136968.0000 - val_loss: 2939300.7500\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 280ms/step - loss: 16662886.6667 - val_loss: 2765881.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 16172073.0000 - val_loss: 2642803.2500\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 15738359.3333 - val_loss: 2574195.5000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 15384748.6667 - val_loss: 2588429.2500\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 15535781.6667 - val_loss: 2153216.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 15071853.3333 - val_loss: 2201847.7500\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 14909302.6667 - val_loss: 2259406.2500\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 14835822.6667 - val_loss: 2045863.5000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 14543187.3333 - val_loss: 2212336.2500\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 14247691.3333 - val_loss: 2076949.3750\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 14237325.3333 - val_loss: 1930950.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 282ms/step - loss: 13961142.0000 - val_loss: 1928542.5000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 13955052.0000 - val_loss: 2190449.7500\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 13769271.3333 - val_loss: 2015567.3750\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 13519258.3333 - val_loss: 2023125.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 13557966.6667 - val_loss: 1894054.5000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 13480526.6667 - val_loss: 1879030.2500\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 267ms/step - loss: 13242780.6667 - val_loss: 1967930.5000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 13316480.6667 - val_loss: 1760730.6250\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 13158071.3333 - val_loss: 1951015.5000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 13053941.3333 - val_loss: 1947035.1250\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 12891954.0000 - val_loss: 1820395.3750\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 13077434.0000 - val_loss: 1917434.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 12743226.6667 - val_loss: 1875754.8750\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 296ms/step - loss: 12912500.6667 - val_loss: 1744902.8750\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 307ms/step - loss: 12467712.3333 - val_loss: 1816024.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 12365412.3333 - val_loss: 1741575.8750\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 12376290.0000 - val_loss: 1939888.6250\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 12124087.0000 - val_loss: 1758657.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa4e509550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [df[num_cols].values] + [df[x].values for x in cat_cols]\n",
    "ae.fit(inputs, inputs,\n",
    "      epochs=100,\n",
    "      batch_size=16384,\n",
    "      shuffle=True,\n",
    "      validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36457, 64)\n"
     ]
    }
   ],
   "source": [
    "encoding = encoder.predict(inputs)\n",
    "print(encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trn = train.shape[0]\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26457, 87) (10000, 87)\n"
     ]
    }
   ],
   "source": [
    "df_enc = pd.concat([df[feature_cols], pd.DataFrame(encoding, columns=[f'enc_{x}' for x in range(encoding_dim)])], axis=1)\n",
    "df_enc['credit'] =train[TARGET]\n",
    "train_enc = df_enc.iloc[:n_trn]\n",
    "test_enc = df_enc.iloc[n_trn:]\n",
    "print(train_enc.shape, test_enc.shape)\n",
    "\n",
    "del train, test, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_enc = train_enc[train_enc['child_num']<=5].reset_index(drop=True) # outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26457, 87)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_enc.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_enc['credit']\n",
    "train_enc.drop('credit',axis=1, inplace=True)\n",
    "test_enc.drop('credit',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(train, y, test, features, model, folds=5):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, random_state=random.randint(1,1000), shuffle=True)\n",
    "    \n",
    "    x_train = train[features]\n",
    "    x_test = test[features]\n",
    "\n",
    "    y_preds = np.zeros((x_test.shape[0],3))\n",
    "    y_oof = np.zeros((x_train.shape[0],3))\n",
    "    \n",
    "    score = 0\n",
    "\n",
    "    features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(x_train, y)):\n",
    "        print(f'Fold: {fold+1}')\n",
    "\n",
    "        x_tr, x_val = x_train.loc[tr_idx, features], x_train.loc[val_idx, features]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        print(x_tr.shape, x_val.shape)\n",
    "        model.fit(x_tr, y_tr, eval_set=[(x_tr, y_tr),(x_val, y_val)], early_stopping_rounds = 50, verbose=50)\n",
    "        \n",
    "        fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "        fold_importance_df['Feature']= features\n",
    "        fold_importance_df['Importance']= model.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n",
    "        \n",
    "        y_pred_val = model.predict_proba(x_val)\n",
    "        y_oof[val_idx] = y_pred_val\n",
    "        print(f\"Fold {fold + 1} | log_loss Score: {log_loss(y_val, y_pred_val)}\")\n",
    "\n",
    "        score += log_loss(y_val, y_pred_val) / folds\n",
    "        y_preds += model.predict_proba(x_test) / folds\n",
    "\n",
    "        del x_tr, x_val, y_tr, y_val\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"\\nMean log_loss Score = {score}\")\n",
    "    print(f\"OOF log_loss Score = {log_loss(y, y_oof)}\")\n",
    "    \n",
    "#     return y_oof, y_preds, features_importance\n",
    "    return y_preds\n",
    "\n",
    "lgb_params = {\n",
    "    'objective':'multiclass',\n",
    "    'num_class': 3,\n",
    "    'boosting_type':'gbdt',\n",
    "    'metric':'multi_logloss',\n",
    "    'n_jobs':-1,\n",
    "    'learning_rate':0.01,\n",
    "    'num_leaves': 1024,\n",
    "    'max_depth':-1,\n",
    "    'tree_learner':'feature',\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample_freq':1,\n",
    "    'subsample':0.8,\n",
    "    'n_estimators':10000\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 10000,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.05,\n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': -1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric':'mlogloss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LGBMClassifier(**lgb_params, seed=random.randint(1,10000)),\n",
    "    LGBMClassifier(**lgb_params, seed=random.randint(1,10000)),\n",
    "    XGBClassifier(**xgb_params, random_state=random.randint(1,10000)),\n",
    "    XGBClassifier(**xgb_params, random_state=random.randint(1,10000))\n",
    "]\n",
    "# lgb_clf = LGBMClassifier(**lgb_params)\n",
    "# xgb_clf = XGBClassifier(**xgb_params)\n",
    "# y_oof_lgb, y_preds_lgb, fi_lgb = make_prediction(train_enc, y, test_enc, train_enc.columns, lgb_clf)\n",
    "# y_oof_xgb, y_preds_xgb, fi_xgb = make_prediction(train_enc, y, test_enc, train_enc.columns, xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "(21165, 86) (5292, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.699822\tvalid_1's multi_logloss: 0.787428\n",
      "[100]\ttraining's multi_logloss: 0.586156\tvalid_1's multi_logloss: 0.744082\n",
      "[150]\ttraining's multi_logloss: 0.503186\tvalid_1's multi_logloss: 0.721877\n",
      "[200]\ttraining's multi_logloss: 0.43995\tvalid_1's multi_logloss: 0.712655\n",
      "[250]\ttraining's multi_logloss: 0.389003\tvalid_1's multi_logloss: 0.710967\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's multi_logloss: 0.395657\tvalid_1's multi_logloss: 0.710567\n",
      "Fold 1 | log_loss Score: 0.7105669833783752\n",
      "Fold: 2\n",
      "(21165, 86) (5292, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.699028\tvalid_1's multi_logloss: 0.792789\n",
      "[100]\ttraining's multi_logloss: 0.585048\tvalid_1's multi_logloss: 0.752675\n",
      "[150]\ttraining's multi_logloss: 0.501875\tvalid_1's multi_logloss: 0.733358\n",
      "[200]\ttraining's multi_logloss: 0.438132\tvalid_1's multi_logloss: 0.725124\n",
      "[250]\ttraining's multi_logloss: 0.386751\tvalid_1's multi_logloss: 0.724746\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttraining's multi_logloss: 0.40923\tvalid_1's multi_logloss: 0.724396\n",
      "Fold 2 | log_loss Score: 0.7243964271454265\n",
      "Fold: 3\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.700511\tvalid_1's multi_logloss: 0.789294\n",
      "[100]\ttraining's multi_logloss: 0.586623\tvalid_1's multi_logloss: 0.745146\n",
      "[150]\ttraining's multi_logloss: 0.503164\tvalid_1's multi_logloss: 0.72326\n",
      "[200]\ttraining's multi_logloss: 0.43955\tvalid_1's multi_logloss: 0.713827\n",
      "[250]\ttraining's multi_logloss: 0.388266\tvalid_1's multi_logloss: 0.71161\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's multi_logloss: 0.395877\tvalid_1's multi_logloss: 0.711505\n",
      "Fold 3 | log_loss Score: 0.7115047440795284\n",
      "Fold: 4\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.699462\tvalid_1's multi_logloss: 0.787084\n",
      "[100]\ttraining's multi_logloss: 0.585566\tvalid_1's multi_logloss: 0.744672\n",
      "[150]\ttraining's multi_logloss: 0.502035\tvalid_1's multi_logloss: 0.722449\n",
      "[200]\ttraining's multi_logloss: 0.43828\tvalid_1's multi_logloss: 0.713939\n",
      "[250]\ttraining's multi_logloss: 0.387037\tvalid_1's multi_logloss: 0.7128\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's multi_logloss: 0.402293\tvalid_1's multi_logloss: 0.712451\n",
      "Fold 4 | log_loss Score: 0.7124512223443773\n",
      "Fold: 5\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.700017\tvalid_1's multi_logloss: 0.788662\n",
      "[100]\ttraining's multi_logloss: 0.586855\tvalid_1's multi_logloss: 0.74552\n",
      "[150]\ttraining's multi_logloss: 0.503671\tvalid_1's multi_logloss: 0.72271\n",
      "[200]\ttraining's multi_logloss: 0.440385\tvalid_1's multi_logloss: 0.71229\n",
      "[250]\ttraining's multi_logloss: 0.388927\tvalid_1's multi_logloss: 0.709849\n",
      "[300]\ttraining's multi_logloss: 0.346322\tvalid_1's multi_logloss: 0.7123\n",
      "Early stopping, best iteration is:\n",
      "[252]\ttraining's multi_logloss: 0.387152\tvalid_1's multi_logloss: 0.709713\n",
      "Fold 5 | log_loss Score: 0.7097133497734612\n",
      "\n",
      "Mean log_loss Score = 0.7137265453442336\n",
      "OOF log_loss Score = 0.713726829213147\n",
      "Fold: 1\n",
      "(21165, 86) (5292, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.700177\tvalid_1's multi_logloss: 0.786368\n",
      "[100]\ttraining's multi_logloss: 0.585442\tvalid_1's multi_logloss: 0.74271\n",
      "[150]\ttraining's multi_logloss: 0.50361\tvalid_1's multi_logloss: 0.721534\n",
      "[200]\ttraining's multi_logloss: 0.439652\tvalid_1's multi_logloss: 0.712858\n",
      "[250]\ttraining's multi_logloss: 0.387848\tvalid_1's multi_logloss: 0.710812\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's multi_logloss: 0.389696\tvalid_1's multi_logloss: 0.710715\n",
      "Fold 1 | log_loss Score: 0.7107152844302417\n",
      "Fold: 2\n",
      "(21165, 86) (5292, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.701063\tvalid_1's multi_logloss: 0.796053\n",
      "[100]\ttraining's multi_logloss: 0.585337\tvalid_1's multi_logloss: 0.75578\n",
      "[150]\ttraining's multi_logloss: 0.502338\tvalid_1's multi_logloss: 0.734898\n",
      "[200]\ttraining's multi_logloss: 0.438155\tvalid_1's multi_logloss: 0.726495\n",
      "[250]\ttraining's multi_logloss: 0.386887\tvalid_1's multi_logloss: 0.725115\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's multi_logloss: 0.403152\tvalid_1's multi_logloss: 0.724916\n",
      "Fold 2 | log_loss Score: 0.7249161449987168\n",
      "Fold: 3\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.69887\tvalid_1's multi_logloss: 0.791604\n",
      "[100]\ttraining's multi_logloss: 0.583824\tvalid_1's multi_logloss: 0.749958\n",
      "[150]\ttraining's multi_logloss: 0.501645\tvalid_1's multi_logloss: 0.729808\n",
      "[200]\ttraining's multi_logloss: 0.43769\tvalid_1's multi_logloss: 0.721839\n",
      "[250]\ttraining's multi_logloss: 0.385919\tvalid_1's multi_logloss: 0.720493\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's multi_logloss: 0.398213\tvalid_1's multi_logloss: 0.720159\n",
      "Fold 3 | log_loss Score: 0.7201586135624443\n",
      "Fold: 4\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.702308\tvalid_1's multi_logloss: 0.788014\n",
      "[100]\ttraining's multi_logloss: 0.587526\tvalid_1's multi_logloss: 0.742398\n",
      "[150]\ttraining's multi_logloss: 0.505004\tvalid_1's multi_logloss: 0.720409\n",
      "[200]\ttraining's multi_logloss: 0.440768\tvalid_1's multi_logloss: 0.710271\n",
      "[250]\ttraining's multi_logloss: 0.388999\tvalid_1's multi_logloss: 0.706745\n",
      "[300]\ttraining's multi_logloss: 0.345875\tvalid_1's multi_logloss: 0.70943\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttraining's multi_logloss: 0.388999\tvalid_1's multi_logloss: 0.706745\n",
      "Fold 4 | log_loss Score: 0.7067448961578633\n",
      "Fold: 5\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.701384\tvalid_1's multi_logloss: 0.787449\n",
      "[100]\ttraining's multi_logloss: 0.586779\tvalid_1's multi_logloss: 0.742519\n",
      "[150]\ttraining's multi_logloss: 0.504865\tvalid_1's multi_logloss: 0.720986\n",
      "[200]\ttraining's multi_logloss: 0.440963\tvalid_1's multi_logloss: 0.710074\n",
      "[250]\ttraining's multi_logloss: 0.38971\tvalid_1's multi_logloss: 0.706978\n",
      "[300]\ttraining's multi_logloss: 0.346786\tvalid_1's multi_logloss: 0.708747\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's multi_logloss: 0.371931\tvalid_1's multi_logloss: 0.706818\n",
      "Fold 5 | log_loss Score: 0.7068176848041136\n",
      "\n",
      "Mean log_loss Score = 0.7138705247906759\n",
      "OOF log_loss Score = 0.713870823024786\n",
      "Fold: 1\n",
      "(21165, 86) (5292, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.700165\tvalid_1's multi_logloss: 0.789487\n",
      "[100]\ttraining's multi_logloss: 0.585662\tvalid_1's multi_logloss: 0.747213\n",
      "[150]\ttraining's multi_logloss: 0.502724\tvalid_1's multi_logloss: 0.726769\n",
      "[200]\ttraining's multi_logloss: 0.439054\tvalid_1's multi_logloss: 0.718225\n",
      "[250]\ttraining's multi_logloss: 0.387298\tvalid_1's multi_logloss: 0.716954\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's multi_logloss: 0.39983\tvalid_1's multi_logloss: 0.716808\n",
      "Fold 1 | log_loss Score: 0.7168077297134211\n",
      "Fold: 2\n",
      "(21165, 86) (5292, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.699219\tvalid_1's multi_logloss: 0.788768\n",
      "[100]\ttraining's multi_logloss: 0.584992\tvalid_1's multi_logloss: 0.745806\n",
      "[150]\ttraining's multi_logloss: 0.502269\tvalid_1's multi_logloss: 0.723078\n",
      "[200]\ttraining's multi_logloss: 0.438668\tvalid_1's multi_logloss: 0.713598\n",
      "[250]\ttraining's multi_logloss: 0.387376\tvalid_1's multi_logloss: 0.711534\n",
      "[300]\ttraining's multi_logloss: 0.344861\tvalid_1's multi_logloss: 0.713832\n",
      "Early stopping, best iteration is:\n",
      "[252]\ttraining's multi_logloss: 0.385542\tvalid_1's multi_logloss: 0.711435\n",
      "Fold 2 | log_loss Score: 0.7114346305243385\n",
      "Fold: 3\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.700595\tvalid_1's multi_logloss: 0.789016\n",
      "[100]\ttraining's multi_logloss: 0.587097\tvalid_1's multi_logloss: 0.745466\n",
      "[150]\ttraining's multi_logloss: 0.50476\tvalid_1's multi_logloss: 0.723593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's multi_logloss: 0.441075\tvalid_1's multi_logloss: 0.713455\n",
      "[250]\ttraining's multi_logloss: 0.389917\tvalid_1's multi_logloss: 0.710893\n",
      "[300]\ttraining's multi_logloss: 0.347246\tvalid_1's multi_logloss: 0.712222\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's multi_logloss: 0.372058\tvalid_1's multi_logloss: 0.710771\n",
      "Fold 3 | log_loss Score: 0.7107713898756125\n",
      "Fold: 4\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.699068\tvalid_1's multi_logloss: 0.788275\n",
      "[100]\ttraining's multi_logloss: 0.584404\tvalid_1's multi_logloss: 0.745035\n",
      "[150]\ttraining's multi_logloss: 0.501652\tvalid_1's multi_logloss: 0.724291\n",
      "[200]\ttraining's multi_logloss: 0.437792\tvalid_1's multi_logloss: 0.716598\n",
      "[250]\ttraining's multi_logloss: 0.386474\tvalid_1's multi_logloss: 0.716293\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's multi_logloss: 0.420354\tvalid_1's multi_logloss: 0.715641\n",
      "Fold 4 | log_loss Score: 0.7156407817991176\n",
      "Fold: 5\n",
      "(21166, 86) (5291, 86)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.700479\tvalid_1's multi_logloss: 0.790949\n",
      "[100]\ttraining's multi_logloss: 0.585964\tvalid_1's multi_logloss: 0.749159\n",
      "[150]\ttraining's multi_logloss: 0.502695\tvalid_1's multi_logloss: 0.728065\n",
      "[200]\ttraining's multi_logloss: 0.438583\tvalid_1's multi_logloss: 0.719381\n",
      "[250]\ttraining's multi_logloss: 0.386872\tvalid_1's multi_logloss: 0.717812\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's multi_logloss: 0.390642\tvalid_1's multi_logloss: 0.717697\n",
      "Fold 5 | log_loss Score: 0.7176969942743486\n",
      "\n",
      "Mean log_loss Score = 0.7144703052373675\n",
      "OOF log_loss Score = 0.7144702788454775\n",
      "Fold: 1\n",
      "(21165, 86) (5292, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07547\tvalidation_1-mlogloss:1.07753\n",
      "[50]\tvalidation_0-mlogloss:0.69236\tvalidation_1-mlogloss:0.78217\n",
      "[100]\tvalidation_0-mlogloss:0.60329\tvalidation_1-mlogloss:0.75426\n",
      "[150]\tvalidation_0-mlogloss:0.53928\tvalidation_1-mlogloss:0.73878\n",
      "[200]\tvalidation_0-mlogloss:0.49173\tvalidation_1-mlogloss:0.73108\n",
      "[250]\tvalidation_0-mlogloss:0.45222\tvalidation_1-mlogloss:0.72600\n",
      "[300]\tvalidation_0-mlogloss:0.41824\tvalidation_1-mlogloss:0.72462\n",
      "[350]\tvalidation_0-mlogloss:0.38791\tvalidation_1-mlogloss:0.72549\n",
      "[360]\tvalidation_0-mlogloss:0.38257\tvalidation_1-mlogloss:0.72552\n",
      "Fold 1 | log_loss Score: 0.72459341297704\n",
      "Fold: 2\n",
      "(21165, 86) (5292, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07537\tvalidation_1-mlogloss:1.07773\n",
      "[50]\tvalidation_0-mlogloss:0.69125\tvalidation_1-mlogloss:0.78156\n",
      "[100]\tvalidation_0-mlogloss:0.59918\tvalidation_1-mlogloss:0.75006\n",
      "[150]\tvalidation_0-mlogloss:0.54000\tvalidation_1-mlogloss:0.73502\n",
      "[200]\tvalidation_0-mlogloss:0.49346\tvalidation_1-mlogloss:0.72627\n",
      "[250]\tvalidation_0-mlogloss:0.45471\tvalidation_1-mlogloss:0.72201\n",
      "[300]\tvalidation_0-mlogloss:0.42221\tvalidation_1-mlogloss:0.71988\n",
      "[350]\tvalidation_0-mlogloss:0.39273\tvalidation_1-mlogloss:0.71905\n",
      "[376]\tvalidation_0-mlogloss:0.37779\tvalidation_1-mlogloss:0.71966\n",
      "Fold 2 | log_loss Score: 0.7187735560944604\n",
      "Fold: 3\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07395\tvalidation_1-mlogloss:1.07580\n",
      "[50]\tvalidation_0-mlogloss:0.70577\tvalidation_1-mlogloss:0.77891\n",
      "[100]\tvalidation_0-mlogloss:0.61457\tvalidation_1-mlogloss:0.74200\n",
      "[150]\tvalidation_0-mlogloss:0.54947\tvalidation_1-mlogloss:0.72118\n",
      "[200]\tvalidation_0-mlogloss:0.50169\tvalidation_1-mlogloss:0.71007\n",
      "[250]\tvalidation_0-mlogloss:0.46426\tvalidation_1-mlogloss:0.70256\n",
      "[300]\tvalidation_0-mlogloss:0.43053\tvalidation_1-mlogloss:0.69891\n",
      "[350]\tvalidation_0-mlogloss:0.39999\tvalidation_1-mlogloss:0.69730\n",
      "[400]\tvalidation_0-mlogloss:0.37233\tvalidation_1-mlogloss:0.69770\n",
      "[425]\tvalidation_0-mlogloss:0.36113\tvalidation_1-mlogloss:0.69823\n",
      "Fold 3 | log_loss Score: 0.696894006761915\n",
      "Fold: 4\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07383\tvalidation_1-mlogloss:1.07587\n",
      "[50]\tvalidation_0-mlogloss:0.70197\tvalidation_1-mlogloss:0.78134\n",
      "[100]\tvalidation_0-mlogloss:0.60693\tvalidation_1-mlogloss:0.74698\n",
      "[150]\tvalidation_0-mlogloss:0.54642\tvalidation_1-mlogloss:0.73199\n",
      "[200]\tvalidation_0-mlogloss:0.49470\tvalidation_1-mlogloss:0.72190\n",
      "[250]\tvalidation_0-mlogloss:0.45507\tvalidation_1-mlogloss:0.71691\n",
      "[300]\tvalidation_0-mlogloss:0.42034\tvalidation_1-mlogloss:0.71365\n",
      "[350]\tvalidation_0-mlogloss:0.39136\tvalidation_1-mlogloss:0.71323\n",
      "[400]\tvalidation_0-mlogloss:0.36382\tvalidation_1-mlogloss:0.71573\n",
      "[405]\tvalidation_0-mlogloss:0.36139\tvalidation_1-mlogloss:0.71580\n",
      "Fold 4 | log_loss Score: 0.7130658771074214\n",
      "Fold: 5\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07390\tvalidation_1-mlogloss:1.07582\n",
      "[50]\tvalidation_0-mlogloss:0.69491\tvalidation_1-mlogloss:0.77478\n",
      "[100]\tvalidation_0-mlogloss:0.60407\tvalidation_1-mlogloss:0.74048\n",
      "[150]\tvalidation_0-mlogloss:0.54636\tvalidation_1-mlogloss:0.72496\n",
      "[200]\tvalidation_0-mlogloss:0.49735\tvalidation_1-mlogloss:0.71420\n",
      "[250]\tvalidation_0-mlogloss:0.45836\tvalidation_1-mlogloss:0.70774\n",
      "[300]\tvalidation_0-mlogloss:0.42427\tvalidation_1-mlogloss:0.70487\n",
      "[350]\tvalidation_0-mlogloss:0.39545\tvalidation_1-mlogloss:0.70356\n",
      "[382]\tvalidation_0-mlogloss:0.37860\tvalidation_1-mlogloss:0.70358\n",
      "Fold 5 | log_loss Score: 0.7034706010324259\n",
      "\n",
      "Mean log_loss Score = 0.7113594907946527\n",
      "OOF log_loss Score = 0.7113602797744903\n",
      "Fold: 1\n",
      "(21165, 86) (5292, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07389\tvalidation_1-mlogloss:1.07587\n",
      "[50]\tvalidation_0-mlogloss:0.69705\tvalidation_1-mlogloss:0.78321\n",
      "[100]\tvalidation_0-mlogloss:0.60849\tvalidation_1-mlogloss:0.75270\n",
      "[150]\tvalidation_0-mlogloss:0.54897\tvalidation_1-mlogloss:0.73650\n",
      "[200]\tvalidation_0-mlogloss:0.50407\tvalidation_1-mlogloss:0.72581\n",
      "[250]\tvalidation_0-mlogloss:0.46456\tvalidation_1-mlogloss:0.72078\n",
      "[300]\tvalidation_0-mlogloss:0.43126\tvalidation_1-mlogloss:0.71865\n",
      "[350]\tvalidation_0-mlogloss:0.40149\tvalidation_1-mlogloss:0.71772\n",
      "[400]\tvalidation_0-mlogloss:0.37558\tvalidation_1-mlogloss:0.71899\n",
      "[405]\tvalidation_0-mlogloss:0.37275\tvalidation_1-mlogloss:0.71932\n",
      "Fold 1 | log_loss Score: 0.7175828295192123\n",
      "Fold: 2\n",
      "(21165, 86) (5292, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07406\tvalidation_1-mlogloss:1.07541\n",
      "[50]\tvalidation_0-mlogloss:0.70759\tvalidation_1-mlogloss:0.77502\n",
      "[100]\tvalidation_0-mlogloss:0.61615\tvalidation_1-mlogloss:0.74113\n",
      "[150]\tvalidation_0-mlogloss:0.54890\tvalidation_1-mlogloss:0.72345\n",
      "[200]\tvalidation_0-mlogloss:0.50301\tvalidation_1-mlogloss:0.71360\n",
      "[250]\tvalidation_0-mlogloss:0.46351\tvalidation_1-mlogloss:0.70753\n",
      "[300]\tvalidation_0-mlogloss:0.42973\tvalidation_1-mlogloss:0.70460\n",
      "[350]\tvalidation_0-mlogloss:0.39978\tvalidation_1-mlogloss:0.70421\n",
      "[375]\tvalidation_0-mlogloss:0.38521\tvalidation_1-mlogloss:0.70444\n",
      "Fold 2 | log_loss Score: 0.7036400748911656\n",
      "Fold: 3\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07404\tvalidation_1-mlogloss:1.07589\n",
      "[50]\tvalidation_0-mlogloss:0.70061\tvalidation_1-mlogloss:0.77985\n",
      "[100]\tvalidation_0-mlogloss:0.61370\tvalidation_1-mlogloss:0.74887\n",
      "[150]\tvalidation_0-mlogloss:0.54996\tvalidation_1-mlogloss:0.73203\n",
      "[200]\tvalidation_0-mlogloss:0.50127\tvalidation_1-mlogloss:0.72089\n",
      "[250]\tvalidation_0-mlogloss:0.45931\tvalidation_1-mlogloss:0.71480\n",
      "[300]\tvalidation_0-mlogloss:0.42546\tvalidation_1-mlogloss:0.71240\n",
      "[350]\tvalidation_0-mlogloss:0.39551\tvalidation_1-mlogloss:0.71204\n",
      "[374]\tvalidation_0-mlogloss:0.38333\tvalidation_1-mlogloss:0.71230\n",
      "Fold 3 | log_loss Score: 0.7119177941925031\n",
      "Fold: 4\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07388\tvalidation_1-mlogloss:1.07560\n",
      "[50]\tvalidation_0-mlogloss:0.69228\tvalidation_1-mlogloss:0.77374\n",
      "[100]\tvalidation_0-mlogloss:0.60069\tvalidation_1-mlogloss:0.74101\n",
      "[150]\tvalidation_0-mlogloss:0.53735\tvalidation_1-mlogloss:0.72527\n",
      "[200]\tvalidation_0-mlogloss:0.49021\tvalidation_1-mlogloss:0.71669\n",
      "[250]\tvalidation_0-mlogloss:0.45118\tvalidation_1-mlogloss:0.71165\n",
      "[300]\tvalidation_0-mlogloss:0.41637\tvalidation_1-mlogloss:0.70967\n",
      "[350]\tvalidation_0-mlogloss:0.38879\tvalidation_1-mlogloss:0.71011\n",
      "[364]\tvalidation_0-mlogloss:0.38138\tvalidation_1-mlogloss:0.71043\n",
      "Fold 4 | log_loss Score: 0.7094024692682654\n",
      "Fold: 5\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07367\tvalidation_1-mlogloss:1.07614\n",
      "[50]\tvalidation_0-mlogloss:0.69222\tvalidation_1-mlogloss:0.78866\n",
      "[100]\tvalidation_0-mlogloss:0.59894\tvalidation_1-mlogloss:0.75640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalidation_0-mlogloss:0.53135\tvalidation_1-mlogloss:0.73961\n",
      "[200]\tvalidation_0-mlogloss:0.48623\tvalidation_1-mlogloss:0.73160\n",
      "[250]\tvalidation_0-mlogloss:0.44548\tvalidation_1-mlogloss:0.72767\n",
      "[300]\tvalidation_0-mlogloss:0.41131\tvalidation_1-mlogloss:0.72629\n",
      "[350]\tvalidation_0-mlogloss:0.38130\tvalidation_1-mlogloss:0.72638\n",
      "[364]\tvalidation_0-mlogloss:0.37470\tvalidation_1-mlogloss:0.72692\n",
      "Fold 5 | log_loss Score: 0.7258398347563987\n",
      "\n",
      "Mean log_loss Score = 0.7136766005255091\n",
      "OOF log_loss Score = 0.7136763773968463\n",
      "Fold: 1\n",
      "(21165, 86) (5292, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07623\tvalidation_1-mlogloss:1.07880\n",
      "[50]\tvalidation_0-mlogloss:0.69442\tvalidation_1-mlogloss:0.77685\n",
      "[100]\tvalidation_0-mlogloss:0.60448\tvalidation_1-mlogloss:0.74268\n",
      "[150]\tvalidation_0-mlogloss:0.54580\tvalidation_1-mlogloss:0.72545\n",
      "[200]\tvalidation_0-mlogloss:0.49983\tvalidation_1-mlogloss:0.71462\n",
      "[250]\tvalidation_0-mlogloss:0.45791\tvalidation_1-mlogloss:0.70768\n",
      "[300]\tvalidation_0-mlogloss:0.42398\tvalidation_1-mlogloss:0.70376\n",
      "[350]\tvalidation_0-mlogloss:0.39485\tvalidation_1-mlogloss:0.70253\n",
      "[400]\tvalidation_0-mlogloss:0.36968\tvalidation_1-mlogloss:0.70238\n",
      "[448]\tvalidation_0-mlogloss:0.34823\tvalidation_1-mlogloss:0.70354\n",
      "Fold 1 | log_loss Score: 0.7023140783166514\n",
      "Fold: 2\n",
      "(21165, 86) (5292, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07577\tvalidation_1-mlogloss:1.07825\n",
      "[50]\tvalidation_0-mlogloss:0.70033\tvalidation_1-mlogloss:0.78272\n",
      "[100]\tvalidation_0-mlogloss:0.60872\tvalidation_1-mlogloss:0.74911\n",
      "[150]\tvalidation_0-mlogloss:0.54506\tvalidation_1-mlogloss:0.73189\n",
      "[200]\tvalidation_0-mlogloss:0.49652\tvalidation_1-mlogloss:0.72203\n",
      "[250]\tvalidation_0-mlogloss:0.45470\tvalidation_1-mlogloss:0.71680\n",
      "[300]\tvalidation_0-mlogloss:0.42097\tvalidation_1-mlogloss:0.71484\n",
      "[350]\tvalidation_0-mlogloss:0.39152\tvalidation_1-mlogloss:0.71502\n",
      "[367]\tvalidation_0-mlogloss:0.38271\tvalidation_1-mlogloss:0.71521\n",
      "Fold 2 | log_loss Score: 0.7143566240611094\n",
      "Fold: 3\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07365\tvalidation_1-mlogloss:1.07585\n",
      "[50]\tvalidation_0-mlogloss:0.69595\tvalidation_1-mlogloss:0.78194\n",
      "[100]\tvalidation_0-mlogloss:0.60234\tvalidation_1-mlogloss:0.75056\n",
      "[150]\tvalidation_0-mlogloss:0.54095\tvalidation_1-mlogloss:0.73581\n",
      "[200]\tvalidation_0-mlogloss:0.49220\tvalidation_1-mlogloss:0.72693\n",
      "[250]\tvalidation_0-mlogloss:0.45213\tvalidation_1-mlogloss:0.72222\n",
      "[300]\tvalidation_0-mlogloss:0.41960\tvalidation_1-mlogloss:0.72076\n",
      "[350]\tvalidation_0-mlogloss:0.38882\tvalidation_1-mlogloss:0.72030\n",
      "[381]\tvalidation_0-mlogloss:0.37261\tvalidation_1-mlogloss:0.72091\n",
      "Fold 3 | log_loss Score: 0.7200123534661594\n",
      "Fold: 4\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07377\tvalidation_1-mlogloss:1.07571\n",
      "[50]\tvalidation_0-mlogloss:0.70103\tvalidation_1-mlogloss:0.77695\n",
      "[100]\tvalidation_0-mlogloss:0.60963\tvalidation_1-mlogloss:0.74310\n",
      "[150]\tvalidation_0-mlogloss:0.54416\tvalidation_1-mlogloss:0.72499\n",
      "[200]\tvalidation_0-mlogloss:0.49690\tvalidation_1-mlogloss:0.71552\n",
      "[250]\tvalidation_0-mlogloss:0.45761\tvalidation_1-mlogloss:0.71046\n",
      "[300]\tvalidation_0-mlogloss:0.42268\tvalidation_1-mlogloss:0.70722\n",
      "[350]\tvalidation_0-mlogloss:0.39330\tvalidation_1-mlogloss:0.70693\n",
      "[391]\tvalidation_0-mlogloss:0.37028\tvalidation_1-mlogloss:0.70866\n",
      "Fold 4 | log_loss Score: 0.7067407780532671\n",
      "Fold: 5\n",
      "(21166, 86) (5291, 86)\n",
      "[0]\tvalidation_0-mlogloss:1.07353\tvalidation_1-mlogloss:1.07561\n",
      "[50]\tvalidation_0-mlogloss:0.69545\tvalidation_1-mlogloss:0.78387\n",
      "[100]\tvalidation_0-mlogloss:0.60502\tvalidation_1-mlogloss:0.75530\n",
      "[150]\tvalidation_0-mlogloss:0.54390\tvalidation_1-mlogloss:0.74083\n",
      "[200]\tvalidation_0-mlogloss:0.49671\tvalidation_1-mlogloss:0.73178\n",
      "[250]\tvalidation_0-mlogloss:0.45694\tvalidation_1-mlogloss:0.72711\n",
      "[300]\tvalidation_0-mlogloss:0.42086\tvalidation_1-mlogloss:0.72596\n",
      "[350]\tvalidation_0-mlogloss:0.39080\tvalidation_1-mlogloss:0.72542\n",
      "[389]\tvalidation_0-mlogloss:0.37050\tvalidation_1-mlogloss:0.72689\n",
      "Fold 5 | log_loss Score: 0.7249067153667591\n",
      "\n",
      "Mean log_loss Score = 0.7136661098527892\n",
      "OOF log_loss Score = 0.713665715496526\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for model in models:\n",
    "    preds.append(make_prediction(train_enc, y, test_enc, train_enc.columns, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:10].index\n",
    "    best_features = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:50]\n",
    "    best_features.reset_index(inplace=True)\n",
    "    print(best_features.dtypes)\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=best_features)\n",
    "    plt.title('Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "# display_importances(fi_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04929144, 0.16305611, 0.78765245],\n",
       "       [0.21066283, 0.31866337, 0.4706738 ],\n",
       "       [0.03900203, 0.05577508, 0.90522289],\n",
       "       ...,\n",
       "       [0.02724279, 0.08480119, 0.88795604],\n",
       "       [0.12620324, 0.34721965, 0.52657711],\n",
       "       [0.07840919, 0.14806037, 0.77353043]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , ..., 1.00000002, 1.        ,\n",
       "       0.99999999])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(preds)/len(preds)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.iloc[:,1:] =  sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission/0513_ensemble_random.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
